from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Train XGBoost to obtain feature importance
feature_cols = [
    f.name for f in prepared_train_df.schema.fields
    if f.name in bool_cols or f.name.endswith("_scaled")
    ][:3]

feature_cols = ["feat1_scaled", "feat2_scaled", "feat3_scaled"]

assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

xgb = SparkXGBClassifier(
    num_workers=spark.sparkContext.defaultParallelism,
    missing=0.0,
    max_depth=2,
    n_estimators=2,
    eval_metric="logloss"
)

paramGrid = ParamGridBuilder()\
  .addGrid(xgb.max_depth, [2])\
  .addGrid(xgb.n_estimators, [2])\
  .build()

evaluator = BinaryClassificationEvaluator()

cv = CrossValidator(estimator=xgb, evaluator=evaluator, estimatorParamMaps=paramGrid, numFolds=2)

pipeline = Pipeline(stages=[assembler, cv])

pipelineModel = pipeline.fit(small_train_df)