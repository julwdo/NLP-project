The TwiBot-22 dataset \citep{feng2022twibot22} is a large-scale benchmark for bot detection on X (formerly Twitter). It contains 1,000,000 users, of which 860,057 are labeled as humans and 139,943 as bots, along with 88,217,457 tweets associated with these users. The dataset also includes information on user connections (edges), enabling both feature-based and graph-based analyses. It is currently one of the most comprehensive publicly available resources for this task.

The tweet data are divided into nine files, each approximately 10â€“11 GB in size. To ensure computational feasibility, only one file was used in this project. The analysis focused on tweets from users included in that file, along with their corresponding user information and labels. The initial stage of feature engineering was performed using the Apache Spark framework, which is well suited for large-scale data processing. The subsequent steps of the analysis were carried out in Python using common data science libraries such as \texttt{pandas}, \texttt{NumPy}, and \texttt{scikit-learn}.

First, a set of user-level features was extracted to capture various aspects of user identity, activity, and profile characteristics. These features are potentially informative for distinguishing between human and bot accounts. Table~\ref{tab:user_features} provides a summary of all extracted features.

Each user was then matched with the corresponding label (bot or human). The user description field was truncated to a maximum of 256 tokens, in accordance with the input limit of the embedding models used in later stages.

In addition to user-level features, tweet-level features were extracted to further enrich the dataset. For efficiency, only the most recent tweets of each user were considered. Specifically, the most recent 10 tweets were used when considering tweets in all languages, while the most recent 20 tweets were used when only English-language tweets were considered.

The extracted features were aggregated at the user level and joined with the previously computed user-level features. For textual features, this involved either concatenating all tweet texts into a single string or collecting them in a list. When concatenating, each tweet was first truncated to a maximum of 12 tokens. For other features, aggregation typically involved computing summary statistics, such as averages or fractions. Table~\ref{tab:tweet_features} provides a summary of all tweet-level features.

IDEA: Remove only 0-importance features and not all below median.