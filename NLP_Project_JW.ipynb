{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fV-2Mc6kjhr3GdesgLaaXJLp6qV5bBC9",
      "authorship_tag": "ABX9TyNHKfDlDRsi/rv1S9WHaxtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julwdo/NLP-project/blob/main/NLP_Project_JW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-17-jdk-headless -qq > /dev/null # OpenJDK 17\n",
        "!wget --show-progress https://dlcdn.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz # Apache Spark 3.5.6 with Hadoop 3 support\n",
        "!tar xf spark-3.5.6-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install -q spark-nlp==6.1.2\n",
        "!pip install -q xgboost==3.0.4\n",
        "!pip install -q --upgrade pyspark==3.5.6"
      ],
      "metadata": {
        "id": "mQ8T-LAUzBeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52f0912-d937-40d5-be9c-a4112bfdc7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-25 11:59:39--  https://dlcdn.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400923510 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.6-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.6-bin-had 100%[===================>] 382.35M   191MB/s    in 2.0s    \n",
            "\n",
            "2025-09-25 11:59:41 (191 MB/s) - ‘spark-3.5.6-bin-hadoop3.tgz’ saved [400923510/400923510]\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/317.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-17-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.5.6-bin-hadoop3'"
      ],
      "metadata": {
        "id": "WHawKcY3TCNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"BotDetection\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:6.1.2\")\n",
        "    .config(\"spark.driver.memory\", \"8g\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "hBPmK_AXjToH",
        "outputId": "1984ea70-34fd-435d-ed6d-02fe8e12e5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x791788759e80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0aac38fce3e7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.6</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>BotDetection</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import math\n",
        "from collections import Counter\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.types import StringType, NumericType, BooleanType, ArrayType, FloatType\n",
        "from sparknlp.base import DocumentAssembler\n",
        "from sparknlp.annotator import XlmRoBertaSentenceEmbeddings\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "J-C_Oc4BzG2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "1dvQfYXH_WoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25633658-fc7e-4718-ca70-8b7cb9c60a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "nXzBU7MKS-dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gcloud init"
      ],
      "metadata": {
        "id": "x3jli8AUVuOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = \"twibot-22\"\n",
        "file_names = [\"user.jsonl\", \"label.csv\", \"tweet_0.jsonl\"]\n",
        "\n",
        "for file_name in file_names:\n",
        "    local_path = f\"/content/{file_name}\"\n",
        "    if not os.path.exists(local_path):\n",
        "        !gsutil cp gs://{bucket_name}/{file_name} {local_path}\n",
        "    else:\n",
        "        print(f\"{file_name} already exists locally, skipping download.\")"
      ],
      "metadata": {
        "id": "T20eeOGhZdsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad99a94-de96-4260-b41e-9507f0513e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://twibot-22/user.jsonl...\n",
            "/ [0 files][    0.0 B/745.4 MiB]                                                \r==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "\\ [1 files][745.4 MiB/745.4 MiB]   67.5 MiB/s                                   \n",
            "Operation completed over 1 objects/745.4 MiB.                                    \n",
            "Copying gs://twibot-22/label.csv...\n",
            "/ [1 files][ 20.6 MiB/ 20.6 MiB]                                                \n",
            "Operation completed over 1 objects/20.6 MiB.                                     \n",
            "Copying gs://twibot-22/tweet_0.jsonl...\n",
            "==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "\\ [1 files][ 11.1 GiB/ 11.1 GiB]  111.4 MiB/s                                   \n",
            "Operation completed over 1 objects/11.1 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users = spark.read.json(f\"/content/user.jsonl\")\n",
        "#users.printSchema()"
      ],
      "metadata": {
        "id": "4ljK4HtA_MmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "zfqG1CcW_Q1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_selected = users.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"name\"),\n",
        "    F.col(\"username\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.col(\"description\"),\n",
        "    F.col(\"url\"),\n",
        "    F.col(\"entities.description.cashtags\"),\n",
        "    F.col(\"entities.description.hashtags\"),\n",
        "    F.col(\"entities.description.mentions\"),\n",
        "    F.col(\"entities.description.urls\"),\n",
        "    F.col(\"location\"),\n",
        "    F.col(\"pinned_tweet_id\"),\n",
        "    F.col(\"profile_image_url\"),\n",
        "    F.col(\"protected\"),\n",
        "    F.col(\"public_metrics.followers_count\"),\n",
        "    F.col(\"public_metrics.following_count\"),\n",
        "    F.col(\"public_metrics.listed_count\"),\n",
        "    F.col(\"public_metrics.tweet_count\"),\n",
        "    F.col(\"verified\")\n",
        "    )"
      ],
      "metadata": {
        "id": "GQAYasduAYqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ce5ND56SEn8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "m1nb1FybEtUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = spark.read.csv(f\"/content/label.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sDJSz4DuE6_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "2S3i6OraGnzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4611f807-95b3-4794-c248-268fe4f43009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|id                  |label|\n",
            "+--------------------+-----+\n",
            "|u1217628182611927040|human|\n",
            "|u2664730894         |human|\n",
            "|u1266703520205549568|human|\n",
            "|u1089159225148882949|human|\n",
            "|u36741729           |bot  |\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_labeled = users_selected.join(labels, users_selected.id == labels.id, \"left\").drop(labels.id)"
      ],
      "metadata": {
        "id": "Dx7pGZ1rGpSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_labeled.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "yxJV0qKaG_Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#users_labeled.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in users_labeled.columns]).show()"
      ],
      "metadata": {
        "id": "e29uv2D-P3Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(text):\n",
        "  return sia.polarity_scores(text)[\"compound\"]\n",
        "\n",
        "vader_udf = F.udf(vader_sentiment, FloatType())"
      ],
      "metadata": {
        "id": "hR9nb9Q6P7CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shannon_entropy(string):\n",
        "    if string.strip() == \"\":\n",
        "        return 0.0\n",
        "    counts = Counter(string)\n",
        "    length = len(string)\n",
        "    return -sum((count/length) * math.log2(count/length) for count in counts.values())\n",
        "\n",
        "entropy_udf = F.udf(shannon_entropy, FloatType())"
      ],
      "metadata": {
        "id": "T9Gc6ww0beC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = F.current_timestamp()"
      ],
      "metadata": {
        "id": "3JkuBNxKOLqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features = users_labeled.select(\n",
        "    F.col(\"id\"),\n",
        "    F.length(F.col(\"name\")).alias(\"name_length\"),\n",
        "    F.length(F.col(\"username\")).alias(\"username_length\"),\n",
        "    (F.length(F.col(\"username\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_length_ratio\"),\n",
        "    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"description\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"description\"),\n",
        "    F.length(F.col(\"description\")).alias(\"description_length\"),\n",
        "    F.when(F.col(\"name\") == \"\", False).otherwise(True).alias(\"has_name\"),\n",
        "    F.when(F.col(\"username\") == \"\", False).otherwise(True).alias(\"has_username\"),\n",
        "    F.when(F.col(\"description\") == \"\", False).otherwise(True).alias(\"has_description\"),\n",
        "    F.when(F.col(\"url\") == \"\", False).otherwise(True).alias(\"has_url\"),\n",
        "    F.when(F.col(\"location\").isNull() | (F.col(\"location\") == \"\"), False).otherwise(True).alias(\"has_location\"),\n",
        "    F.when(F.col(\"pinned_tweet_id\").isNull(), False).otherwise(True).alias(\"has_pinned_tweet\"),\n",
        "    F.col(\"name\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_name\"),\n",
        "    F.col(\"description\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_digits_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_digits_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_digits_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_special_chars_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_special_chars_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_special_chars_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"name\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"name_upper_to_lower_ratio\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"username\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"username_upper_to_lower_ratio\"),\n",
        "    entropy_udf(F.col(\"name\")).alias(\"name_entropy\"),\n",
        "    entropy_udf(F.col(\"username\")).alias(\"username_entropy\"),\n",
        "    (F.levenshtein(F.col(\"username\"), F.col(\"name\")) / F.greatest(F.length(F.col(\"username\")), F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_levenshtein\"),\n",
        "    vader_udf(F.col(\"description\")).alias(\"description_sentiment\"),\n",
        "    F.when(F.col(\"cashtags\").isNotNull(), F.size(F.col(\"cashtags\"))).otherwise(F.lit(0)).alias(\"cashtag_in_description_count\"),\n",
        "    F.when(F.col(\"hashtags\").isNotNull(), F.size(F.col(\"hashtags\"))).otherwise(F.lit(0)).alias(\"hashtag_in_description_count\"),\n",
        "    F.when(F.col(\"mentions\").isNotNull(), F.size(F.col(\"mentions\"))).otherwise(F.lit(0)).alias(\"mention_in_description_count\"),\n",
        "    F.when(F.col(\"urls\").isNotNull(), F.size(F.col(\"urls\"))).otherwise(F.lit(0)).alias(\"url_in_description_count\"),\n",
        "    F.col(\"protected\").alias(\"is_protected\"),\n",
        "    F.col(\"verified\").alias(\"is_verified\"),\n",
        "    (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\"))).alias(\"account_age_seconds\"),\n",
        "    F.col(\"followers_count\"),\n",
        "    F.col(\"following_count\"),\n",
        "    F.col(\"listed_count\"),\n",
        "    F.col(\"tweet_count\"),\n",
        "    (F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"followers_over_following\"),\n",
        "    (2 * F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"double_followers_over_following\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"following_over_followers\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") ** 2, F.lit(1))).alias(\"following_over_followers_squared\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") + F.col(\"following_count\"), F.lit(1))).alias(\"following_over_total_connections\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"listed_over_followers\"),\n",
        "    (F.col(\"tweet_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"tweets_over_followers\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"tweet_count\"), F.lit(1))).alias(\"listed_over_tweets\"),\n",
        "    (F.col(\"followers_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"follower_rate\"),\n",
        "    (F.col(\"following_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"following_rate\"),\n",
        "    (F.col(\"listed_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"listed_rate\"),\n",
        "    (F.col(\"tweet_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"tweet_rate\"),\n",
        "    F.col(\"label\")\n",
        "    )"
      ],
      "metadata": {
        "id": "S2TklOE1NR4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate each description to 128 tokens\n",
        "def truncate_text(text, max_tokens=128):\n",
        "    tokens = text.split()\n",
        "    return \" \".join(tokens[:max_tokens])\n",
        "\n",
        "truncate_udf = F.udf(lambda x: truncate_text(x, 128), StringType())\n",
        "\n",
        "user_truncated = user_features.withColumn(\n",
        "    \"description\", truncate_udf(\"description\")\n",
        ")"
      ],
      "metadata": {
        "id": "rLiEb0uuvtPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user_truncated.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "cNzg48OdN_Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = spark.read.json(f\"/content/tweet_0.jsonl\")\n",
        "#tweets.printSchema()"
      ],
      "metadata": {
        "id": "BoXGa7V54LOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "WQcJouz95AqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_selected = tweets.select(\n",
        "    F.col(\"id\"),\n",
        "    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"text\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"text\"),\n",
        "    F.concat(F.lit(\"u\"), F.col(\"author_id\")).alias(\"author_id\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.when(F.col(\"in_reply_to_user_id\").isNull(), False).otherwise(True).cast(\"int\").alias(\"is_reply\"),\n",
        "    F.col(\"lang\"),\n",
        "    F.col(\"possibly_sensitive\").cast(\"int\").alias(\"is_sensitive\"),\n",
        "    F.col(\"public_metrics.like_count\"),\n",
        "    F.col(\"public_metrics.quote_count\"),\n",
        "    F.col(\"public_metrics.reply_count\"),\n",
        "    F.col(\"public_metrics.retweet_count\")\n",
        "    )"
      ],
      "metadata": {
        "id": "YUIgowMCnixE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ksw3FbI0oI30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "Olt6LrVdNQEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#tweets_selected.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in tweets_selected.columns]).show()"
      ],
      "metadata": {
        "id": "nwL2Tp8gNydF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate each tweet to 12 tokens\n",
        "truncate_udf = F.udf(lambda x: truncate_text(x, 12), StringType())\n",
        "\n",
        "tweets_truncated = tweets_selected.withColumn(\n",
        "    \"text_truncated\", truncate_udf(\"text\")\n",
        ")"
      ],
      "metadata": {
        "id": "7pZaehCh5rWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_truncated.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "BMzhsnkF5txg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter top 10 tweets per author\n",
        "window = Window.partitionBy(\"author_id\").orderBy(F.col(\"created_at\").desc())\n",
        "tweets_truncated = tweets_truncated.withColumn(\"rank\", F.row_number().over(window))\n",
        "tweets_filtered = tweets_truncated.filter(F.col(\"rank\") <= 10).drop(\"rank\")"
      ],
      "metadata": {
        "id": "3jkN_YbEKD1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features = tweets_filtered.groupBy(\"author_id\").agg(\n",
        "    F.concat_ws(\" \", F.collect_list(\"text_truncated\")).alias(\"top_tweets_concatenated_text\"),\n",
        "    F.avg(F.col(\"is_reply\")).alias(\"top_tweets_reply_fraction\"),\n",
        "    F.countDistinct(\"lang\").alias(\"top_tweets_num_distinct_langs\"),\n",
        "    F.avg(F.col(\"is_sensitive\")).alias(\"top_tweets_sensitive_fraction\"),\n",
        "    F.avg(F.col(\"like_count\")).alias(\"top_tweets_avg_likes\"),\n",
        "    F.avg(F.col(\"quote_count\")).alias(\"top_tweets_avg_quotes\"),\n",
        "    F.avg(F.col(\"reply_count\")).alias(\"top_tweets_avg_replies\"),\n",
        "    F.avg(F.col(\"retweet_count\")).alias(\"top_tweets_avg_retweets\")\n",
        "    )"
      ],
      "metadata": {
        "id": "dOdcif7GIdfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join user features with aggregated tweet features\n",
        "enriched_user_features = user_truncated.join(\n",
        "    tweet_features,\n",
        "    user_truncated.id == tweet_features.author_id,\n",
        "    how=\"inner\"\n",
        ").drop(\"author_id\").cache()"
      ],
      "metadata": {
        "id": "ezqCAy0aPDmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enriched_user_features.printSchema()"
      ],
      "metadata": {
        "id": "tw__NrC-khyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enriched_user_features.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "Z4pZW8hmS9cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/TwiBot-22_Processed\"\n",
        "\n",
        "enriched_user_features.write.mode(\"overwrite\").parquet(f\"{path}/enriched_user_features.parquet\")"
      ],
      "metadata": {
        "id": "58f2QM5CcipF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iz2NCbi2wx_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}