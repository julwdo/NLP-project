{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fV-2Mc6kjhr3GdesgLaaXJLp6qV5bBC9",
      "authorship_tag": "ABX9TyPbTJ+1kiQhHHPbTzZzLznB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julwdo/NLP-project/blob/main/NLP_Project_JW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-17-jdk-headless -qq > /dev/null # OpenJDK 17\n",
        "!wget --show-progress https://dlcdn.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz # Apache Spark 3.5.6 with Hadoop 3 support\n",
        "!tar xf spark-3.5.6-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install -q spark-nlp==6.1.2\n",
        "!pip install -q xgboost==3.0.4\n",
        "!pip install -q --upgrade pyspark==3.5.6"
      ],
      "metadata": {
        "id": "mQ8T-LAUzBeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7aa7bf-df3a-40d5-cdeb-361a06d25b67"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-22 16:09:17--  https://dlcdn.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400923510 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.6-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.6-bin-had 100%[===================>] 382.35M   160MB/s    in 2.4s    \n",
            "\n",
            "2025-09-22 16:09:41 (160 MB/s) - ‘spark-3.5.6-bin-hadoop3.tgz’ saved [400923510/400923510]\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/317.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-17-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.5.6-bin-hadoop3'"
      ],
      "metadata": {
        "id": "WHawKcY3TCNK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"BotDetection\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:6.1.2\")\n",
        "    .config(\"spark.driver.memory\", \"8g\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "hBPmK_AXjToH",
        "outputId": "99d5761b-c3fd-4690-bd8e-a9eb9ddf9203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d09b52552b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://11a4c4530b27:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.6</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>BotDetection</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import math\n",
        "from collections import Counter\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.types import StringType, NumericType, BooleanType, ArrayType, FloatType\n",
        "from sparknlp.base import DocumentAssembler\n",
        "from sparknlp.annotator import XlmRoBertaSentenceEmbeddings\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "J-C_Oc4BzG2s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "1dvQfYXH_WoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f9de9b-690a-46c9-c98f-f169eb10f341"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "nXzBU7MKS-dT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!gcloud init"
      ],
      "metadata": {
        "id": "x3jli8AUVuOm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = \"twibot-22\"\n",
        "file_names = [\"user.jsonl\", \"label.csv\", \"tweet_0.jsonl\"]\n",
        "\n",
        "for file_name in file_names:\n",
        "    local_path = f\"/content/{file_name}\"\n",
        "    if not os.path.exists(local_path):\n",
        "        !gsutil cp gs://{bucket_name}/{file_name} {local_path}\n",
        "    else:\n",
        "        print(f\"{file_name} already exists locally, skipping download.\")"
      ],
      "metadata": {
        "id": "T20eeOGhZdsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a479fda9-c7a2-489d-d9d4-527b1f9e7424"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://twibot-22/user.jsonl...\n",
            "/ [0 files][    0.0 B/745.4 MiB]                                                \r==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "/ [1 files][745.4 MiB/745.4 MiB]   32.4 MiB/s                                   \n",
            "Operation completed over 1 objects/745.4 MiB.                                    \n",
            "Copying gs://twibot-22/label.csv...\n",
            "/ [1 files][ 20.6 MiB/ 20.6 MiB]                                                \n",
            "Operation completed over 1 objects/20.6 MiB.                                     \n",
            "Copying gs://twibot-22/tweet_0.jsonl...\n",
            "==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "| [1 files][ 11.1 GiB/ 11.1 GiB]  116.4 MiB/s                                   \n",
            "Operation completed over 1 objects/11.1 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users = spark.read.json(f\"/content/user.jsonl\")\n",
        "#users.printSchema()"
      ],
      "metadata": {
        "id": "4ljK4HtA_MmV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "zfqG1CcW_Q1c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_selected = users.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"name\"),\n",
        "    F.col(\"username\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.col(\"description\"),\n",
        "    F.col(\"url\"),\n",
        "    F.col(\"entities.description.cashtags\"),\n",
        "    F.col(\"entities.description.hashtags\"),\n",
        "    F.col(\"entities.description.mentions\"),\n",
        "    F.col(\"entities.description.urls\"),\n",
        "    F.col(\"location\"),\n",
        "    F.col(\"pinned_tweet_id\"),\n",
        "    F.col(\"profile_image_url\"),\n",
        "    F.col(\"protected\"),\n",
        "    F.col(\"public_metrics.followers_count\"),\n",
        "    F.col(\"public_metrics.following_count\"),\n",
        "    F.col(\"public_metrics.listed_count\"),\n",
        "    F.col(\"public_metrics.tweet_count\"),\n",
        "    F.col(\"verified\")\n",
        "    )"
      ],
      "metadata": {
        "id": "GQAYasduAYqH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ce5ND56SEn8R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "m1nb1FybEtUp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = spark.read.csv(f\"/content/label.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "sDJSz4DuE6_2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "2S3i6OraGnzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99eaa20c-85e1-441f-9046-ad5de38f24a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|id                  |label|\n",
            "+--------------------+-----+\n",
            "|u1217628182611927040|human|\n",
            "|u2664730894         |human|\n",
            "|u1266703520205549568|human|\n",
            "|u1089159225148882949|human|\n",
            "|u36741729           |bot  |\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_labeled = users_selected.join(labels, users_selected.id == labels.id, \"left\").drop(labels.id)"
      ],
      "metadata": {
        "id": "Dx7pGZ1rGpSJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#users_labeled.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "yxJV0qKaG_Et"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#users_labeled.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in users_labeled.columns]).show()"
      ],
      "metadata": {
        "id": "e29uv2D-P3Zz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(text):\n",
        "  return sia.polarity_scores(text)[\"compound\"]\n",
        "\n",
        "vader_udf = F.udf(vader_sentiment, FloatType())"
      ],
      "metadata": {
        "id": "hR9nb9Q6P7CJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shannon_entropy(string):\n",
        "    if string.strip() == \"\":\n",
        "        return 0.0\n",
        "    counts = Counter(string)\n",
        "    length = len(string)\n",
        "    return -sum((count/length) * math.log2(count/length) for count in counts.values())\n",
        "\n",
        "entropy_udf = F.udf(shannon_entropy, FloatType())"
      ],
      "metadata": {
        "id": "T9Gc6ww0beC5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = F.current_timestamp()"
      ],
      "metadata": {
        "id": "3JkuBNxKOLqc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features = users_labeled.select(\n",
        "    F.col(\"id\"),\n",
        "    F.length(F.col(\"name\")).alias(\"name_length\"),\n",
        "    F.length(F.col(\"username\")).alias(\"username_length\"),\n",
        "    (F.length(F.col(\"username\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_length_ratio\"),\n",
        "    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"description\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"description\"),\n",
        "    F.length(F.col(\"description\")).alias(\"description_length\"),\n",
        "    F.when(F.col(\"name\") == \"\", False).otherwise(True).alias(\"has_name\"),\n",
        "    F.when(F.col(\"username\") == \"\", False).otherwise(True).alias(\"has_username\"),\n",
        "    F.when(F.col(\"description\") == \"\", False).otherwise(True).alias(\"has_description\"),\n",
        "    F.when(F.col(\"url\") == \"\", False).otherwise(True).alias(\"has_url\"),\n",
        "    F.when(F.col(\"location\").isNull() | (F.col(\"location\") == \"\"), False).otherwise(True).alias(\"has_location\"),\n",
        "    F.when(F.col(\"pinned_tweet_id\").isNull(), False).otherwise(True).alias(\"has_pinned_tweet\"),\n",
        "    F.col(\"name\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_name\"),\n",
        "    F.col(\"description\").rlike(\"(?i)\\\\bbot\\\\b\").alias(\"has_bot_word_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_digits_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_digits_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[^\\\\d]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_digits_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"name\")), F.lit(1))).alias(\"ratio_special_chars_in_name\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"username\")), F.lit(1))).alias(\"ratio_special_chars_in_username\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"description\"), \"[A-Za-z0-9 ]\", \"\")) / F.greatest(F.length(F.col(\"description\")), F.lit(1))).alias(\"ratio_special_chars_in_description\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"name\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"name\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"name_upper_to_lower_ratio\"),\n",
        "    (F.length(F.regexp_replace(F.col(\"username\"), \"[^A-Z]\", \"\")) / F.greatest(F.length(F.regexp_replace(F.col(\"username\"), \"[^a-z]\", \"\")), F.lit(1))).alias(\"username_upper_to_lower_ratio\"),\n",
        "    entropy_udf(F.col(\"name\")).alias(\"name_entropy\"),\n",
        "    entropy_udf(F.col(\"username\")).alias(\"username_entropy\"),\n",
        "    (F.levenshtein(F.col(\"username\"), F.col(\"name\")) / F.greatest(F.length(F.col(\"username\")), F.length(F.col(\"name\")), F.lit(1))).alias(\"username_name_levenshtein\"),\n",
        "    vader_udf(F.col(\"description\")).alias(\"description_sentiment\"),\n",
        "    F.when(F.col(\"cashtags\").isNotNull(), F.size(F.col(\"cashtags\"))).otherwise(F.lit(0)).alias(\"cashtag_in_description_count\"),\n",
        "    F.when(F.col(\"hashtags\").isNotNull(), F.size(F.col(\"hashtags\"))).otherwise(F.lit(0)).alias(\"hashtag_in_description_count\"),\n",
        "    F.when(F.col(\"mentions\").isNotNull(), F.size(F.col(\"mentions\"))).otherwise(F.lit(0)).alias(\"mention_in_description_count\"),\n",
        "    F.when(F.col(\"urls\").isNotNull(), F.size(F.col(\"urls\"))).otherwise(F.lit(0)).alias(\"url_in_description_count\"),\n",
        "    F.col(\"protected\").alias(\"is_protected\"),\n",
        "    F.col(\"verified\").alias(\"is_verified\"),\n",
        "    (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\"))).alias(\"account_age_seconds\"),\n",
        "#    F.col(\"followers_count\"),\n",
        "#    F.col(\"following_count\"),\n",
        "#    F.col(\"listed_count\"),\n",
        "#    F.col(\"tweet_count\"),\n",
        "    (F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"followers_over_following\"),\n",
        "    (2 * F.col(\"followers_count\") / F.greatest(F.col(\"following_count\"), F.lit(1))).alias(\"double_followers_over_following\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"following_over_followers\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") ** 2, F.lit(1))).alias(\"following_over_followers_squared\"),\n",
        "    (F.col(\"following_count\") / F.greatest(F.col(\"followers_count\") + F.col(\"following_count\"), F.lit(1))).alias(\"following_over_total_connections\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"listed_over_followers\"),\n",
        "    (F.col(\"tweet_count\") / F.greatest(F.col(\"followers_count\"), F.lit(1))).alias(\"tweets_over_followers\"),\n",
        "    (F.col(\"listed_count\") / F.greatest(F.col(\"tweet_count\"), F.lit(1))).alias(\"listed_over_tweets\"),\n",
        "    (F.col(\"followers_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"follower_rate\"),\n",
        "    (F.col(\"following_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"following_rate\"),\n",
        "    (F.col(\"listed_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"listed_rate\"),\n",
        "    (F.col(\"tweet_count\") / (F.unix_timestamp(now) - F.unix_timestamp(F.to_timestamp(\"created_at\")))).alias(\"tweet_rate\"),\n",
        "    F.col(\"label\")\n",
        "    )"
      ],
      "metadata": {
        "id": "S2TklOE1NR4W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user_features.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "cNzg48OdN_Hk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = spark.read.json(f\"/content/tweet_0.jsonl\")\n",
        "#tweets.printSchema()"
      ],
      "metadata": {
        "id": "BoXGa7V54LOz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "WQcJouz95AqR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_selected = tweets.select(\n",
        "    F.col(\"id\"),\n",
        "    F.regexp_replace(F.regexp_replace(F.regexp_replace(F.col(\"text\"), r\"https?://t\\.co/\\S+\", \"<URL>\"), r\"(?<=^|\\s)@\\w+\", \"<USER>\"), r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"<EMAIL>\").alias(\"text\"),\n",
        "    F.concat(F.lit(\"u\"), F.col(\"author_id\")).alias(\"author_id\"),\n",
        "    F.col(\"created_at\"),\n",
        "    F.when(F.col(\"in_reply_to_user_id\").isNull(), False).otherwise(True).cast(\"int\").alias(\"is_reply\"),\n",
        "    F.col(\"lang\"),\n",
        "    F.col(\"possibly_sensitive\").cast(\"int\").alias(\"is_sensitive\"),\n",
        "    F.col(\"public_metrics.like_count\"),\n",
        "    F.col(\"public_metrics.quote_count\"),\n",
        "    F.col(\"public_metrics.reply_count\"),\n",
        "    F.col(\"public_metrics.retweet_count\")\n",
        "    )"
      ],
      "metadata": {
        "id": "YUIgowMCnixE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.printSchema()"
      ],
      "metadata": {
        "id": "Ksw3FbI0oI30"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_selected.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "Olt6LrVdNQEB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('Summary of missing values:')\n",
        "#tweets_selected.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in tweets_selected.columns]).show()"
      ],
      "metadata": {
        "id": "nwL2Tp8gNydF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate each tweet to 25 tokens\n",
        "def truncate_text(text, max_tokens=25):\n",
        "    tokens = text.split()\n",
        "    return \" \".join(tokens[:max_tokens])\n",
        "\n",
        "truncate_udf = F.udf(lambda x: truncate_text(x, 25), StringType())\n",
        "\n",
        "tweets_truncated = tweets_selected.withColumn(\n",
        "    \"text_truncated\", truncate_udf(\"text\")\n",
        ")"
      ],
      "metadata": {
        "id": "7pZaehCh5rWO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweets_truncated.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "BMzhsnkF5txg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter top 20 tweets per author\n",
        "window = Window.partitionBy(\"author_id\").orderBy(F.col(\"created_at\").desc())\n",
        "tweets_truncated = tweets_truncated.withColumn(\"rank\", F.row_number().over(window))\n",
        "tweets_filtered = tweets_truncated.filter(F.col(\"rank\") <= 20).drop(\"rank\")"
      ],
      "metadata": {
        "id": "3jkN_YbEKD1n"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_features = tweets_filtered.groupBy(\"author_id\").agg(\n",
        "    F.concat_ws(\" \", F.collect_list(\"text_truncated\")).alias(\"tweets_last20_concatenated_text\"),\n",
        "    F.avg(F.col(\"is_reply\")).alias(\"tweets_last20_reply_fraction\"),\n",
        "    F.countDistinct(\"lang\").alias(\"tweets_last20_num_distinct_langs\"),\n",
        "    F.avg(F.col(\"is_sensitive\")).alias(\"tweets_last20_sensitive_fraction\"),\n",
        "    F.avg(F.col(\"like_count\")).alias(\"tweets_last20_avg_likes\"),\n",
        "#    F.avg(F.col(\"quote_count\")).alias(\"tweets_last20_avg_quotes\"),\n",
        "#    F.avg(F.col(\"reply_count\")).alias(\"tweets_last20_avg_replies\"),\n",
        "    F.avg(F.col(\"retweet_count\")).alias(\"tweets_last20_avg_retweets\")\n",
        "    )"
      ],
      "metadata": {
        "id": "dOdcif7GIdfN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join user features with aggregated tweet features\n",
        "enriched_user_features = user_features.join(\n",
        "    tweet_features,\n",
        "    user_features.id == tweet_features.author_id,\n",
        "    how=\"inner\"\n",
        ").drop(\"author_id\")"
      ],
      "metadata": {
        "id": "ezqCAy0aPDmS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enriched_user_features.printSchema()"
      ],
      "metadata": {
        "id": "tw__NrC-khyD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enriched_user_features.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "Z4pZW8hmS9cZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = enriched_user_features.select(\n",
        "    F.col(\"id\"),\n",
        "    F.col(\"description\"),\n",
        "    F.col(\"tweets_last20_concatenated_text\")\n",
        ")"
      ],
      "metadata": {
        "id": "EWQmWh43ZDzt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc_doc = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"description_doc\")\n",
        "\n",
        "desc_embed = XlmRoBertaSentenceEmbeddings.pretrained(\"sent_xlm_roberta_base\", \"xx\") \\\n",
        "    .setInputCols([\"description_doc\"]) \\\n",
        "    .setOutputCol(\"description_embeddings\")\n",
        "\n",
        "desc_pipeline = Pipeline(stages=[desc_doc, desc_embed])\n",
        "desc_model = desc_pipeline.fit(text_features)\n",
        "desc_emb = desc_model.transform(text_features).cache()\n",
        "\n",
        "tweets_doc = DocumentAssembler() \\\n",
        "    .setInputCol(\"tweets_last20_concatenated_text\") \\\n",
        "    .setOutputCol(\"tweets_doc\")\n",
        "\n",
        "tweets_embed = XlmRoBertaSentenceEmbeddings.pretrained(\"sent_xlm_roberta_base\", \"xx\") \\\n",
        "    .setInputCols([\"tweets_doc\"]) \\\n",
        "    .setOutputCol(\"tweets_embeddings\")\n",
        "\n",
        "tweets_pipeline = Pipeline(stages=[tweets_doc, tweets_embed])\n",
        "tweets_model = tweets_pipeline.fit(desc_emb)\n",
        "tweets_emb = tweets_model.transform(desc_emb).cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2gAVXStQGOS",
        "outputId": "476be96c-a896-4179-b191-2c01b60f64da"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_xlm_roberta_base download started this may take some time.\n",
            "Approximate size to download 619.5 MB\n",
            "[OK!]\n",
            "sent_xlm_roberta_base download started this may take some time.\n",
            "Approximate size to download 619.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_emb.printSchema()"
      ],
      "metadata": {
        "id": "gKsAYwY1geco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9689e7c6-58e4-4465-c731-18a82d4219d8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- tweets_last20_concatenated_text: string (nullable = false)\n",
            " |-- description_doc: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- description_embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- tweets_doc: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- tweets_embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_module = tweets_emb.select(\n",
        "    \"id\",\n",
        "    F.col(\"description_embeddings\")[0][\"embeddings\"].alias(\"description_vector\"),\n",
        "    F.col(\"tweets_embeddings\")[0][\"embeddings\"].alias(\"tweets_vector\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "MMwSAa93Z7tj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_module = enriched_user_features.drop(\n",
        "    \"description\",\n",
        "    \"tweets_last20_concatenated_text\"\n",
        "    )"
      ],
      "metadata": {
        "id": "wjt0Pw8PDpSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user_module.printSchema()"
      ],
      "metadata": {
        "id": "HBf2D6ATEBJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, validation, test split\n",
        "train_frac = 0.7\n",
        "val_frac = 0.2\n",
        "test_frac = 0.1\n",
        "\n",
        "train_df, val_df, test_df = user_module.randomSplit([train_frac, val_frac, test_frac], seed=42)"
      ],
      "metadata": {
        "id": "YzSLM2tk3R_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize numerical features\n",
        "numeric_cols = [\n",
        "    f.name for f in train_df.schema.fields if isinstance(f.dataType, NumericType)\n",
        "    ]\n",
        "\n",
        "stats_df = train_df.select([\n",
        "    F.mean(c).alias(f\"{c}_mean\") for c in numeric_cols\n",
        "    ] + [\n",
        "        F.stddev(c).alias(f\"{c}_std\") for c in numeric_cols\n",
        "        ])\n",
        "\n",
        "# train_df\n",
        "scaled_train_df = train_df.crossJoin(stats_df)\n",
        "\n",
        "for c in numeric_cols:\n",
        "    scaled_train_df = scaled_train_df.withColumn(f\"{c}_scaled\",\n",
        "     (F.col(c) - F.col(f\"{c}_mean\")) / F.col(f\"{c}_std\"))\n",
        "\n",
        "# val_df\n",
        "scaled_val_df = val_df.crossJoin(stats_df)\n",
        "\n",
        "for c in numeric_cols:\n",
        "    scaled_val_df = scaled_val_df.withColumn(f\"{c}_scaled\",\n",
        "     (F.col(c) - F.col(f\"{c}_mean\")) / F.col(f\"{c}_std\"))\n",
        "\n",
        "# test_df\n",
        "scaled_test_df = test_df.crossJoin(stats_df)\n",
        "\n",
        "for c in numeric_cols:\n",
        "    scaled_test_df = scaled_test_df.withColumn(f\"{c}_scaled\",\n",
        "     (F.col(c) - F.col(f\"{c}_mean\")) / F.col(f\"{c}_std\"))\n",
        "\n",
        "# Select relevant cols\n",
        "cols = [\n",
        "    f.name for f in scaled_train_df.schema.fields\n",
        "    if f.name not in numeric_cols\n",
        "    and not f.name.endswith(\"_mean\")\n",
        "    and not f.name.endswith(\"_std\")\n",
        "]\n",
        "\n",
        "scaled_train_df = scaled_train_df.select(cols)\n",
        "scaled_val_df = scaled_val_df.select(cols)\n",
        "scaled_test_df = scaled_test_df.select(cols)"
      ],
      "metadata": {
        "id": "yexhFmB2TEcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaled_train_df.show(5)"
      ],
      "metadata": {
        "id": "Q2FK7kGxh4tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bool_cols = [\n",
        "    f.name for f in scaled_train_df.schema.fields if isinstance(f.dataType, BooleanType)\n",
        "    ]\n",
        "\n",
        "select_exprs = [\n",
        "    # Cast all boolean columns to double\n",
        "    F.col(c).cast(\"double\").alias(c) for c in bool_cols\n",
        "] + [\n",
        "    # Cast label column: 1 if \"bot\", 0 if \"human\"\n",
        "    F.when(F.col(\"label\") == \"bot\", 1.0).otherwise(0.0).alias(\"label\")\n",
        "] + [\n",
        "    F.col(c) for c in scaled_train_df.columns if c not in bool_cols + [\"label\"]\n",
        "]\n",
        "\n",
        "prepared_train_df = scaled_train_df.select(*select_exprs).cache()\n",
        "prepared_val_df = scaled_val_df.select(*select_exprs).cache()\n",
        "prepared_test_df = scaled_test_df.select(*select_exprs).cache()"
      ],
      "metadata": {
        "id": "JxID6aaS2K67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/TwiBot-22-Processed\"\n",
        "\n",
        "prepared_train_df.write.mode(\"overwrite\").parquet(f\"{path}/prepared_train_df.parquet\")\n",
        "prepared_val_df.write.mode(\"overwrite\").parquet(f\"{path}/prepared_val_df.parquet\")\n",
        "prepared_test_df.write.mode(\"overwrite\").parquet(f\"{path}/prepared_test_df.parquet\")\n",
        "text_module.write.mode(\"overwrite\").parquet(f\"{path}/text_module.parquet\")"
      ],
      "metadata": {
        "id": "qUzW4swbR0WZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_module.write.mode(\"overwrite\").parquet(f\"{path}/text_module.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "DM7wUyvWE-Ae",
        "outputId": "a10eaf2d-f52a-49d1-c5c9-4881fc76f183"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.5.6-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/spark-3.5.6-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 720, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4174964584.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/text_module.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.5.6-bin-hadoop3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1721\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m     def text(\n",
            "\u001b[0;32m/content/spark-3.5.6-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/content/spark-3.5.6-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.6-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6oZtssqID8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}